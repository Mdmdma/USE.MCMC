}
}
}
return(all.matrix)
}
hs <- adci(simout, eval_date=ed, breaks=breaks,
stage="Adults",
sub_stage = "Host-seeking" )
head(hs)
library(gstat)
library(terra)
gridDim <- 20 # 5000m/250 m = 20 columns and rows
xy <- expand.grid(x=1:gridDim, y=1:gridDim)
varioMod <- vgm(psill=0.5, range=100, model='Exp') # psill = partial sill = (sill-nugget)
# Set up an additional variable from simple kriging
zDummy <- gstat(formula=z~1,
locations = ~x+y,
dummy=TRUE,
beta=1,
model=varioMod,
nmax=1)
# Generate a randomly autocorrelated predictor data field
set.seed(123)
xyz <- predict(zDummy, newdata=xy, nsim=1)
utm32N <- "+proj=utm +zone=32 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"
r <- terra::rast(nrow=gridDim, ncol=gridDim, crs=utm32N, ext=terra::ext(1220000,1225000, 5700000,5705000))
terra::values(r) <- xyz$sim1
# plot(r, main="SAC landscape")
# convert to a data.frame
df <- data.frame("id"=1:nrow(xyz), terra::crds(r))
bbox <- terra::as.polygons(terra::ext(r), crs=utm32N)
# Store Parameters for autocorrelation
autocorr_factor <- terra::values(r)
# "expand onto space" the temperature time series by multiplying it with the autocorrelated surface simulated above.
mat <- do.call(rbind, lapply(1:ncell(r), function(x) {
d_t <- sim_temp[[1]]$x*autocorr_factor[[x]]
return(d_t)
}))
# format simulated temperature
names(mat) <- paste0("d_", 1:ndays)
df_temp <- cbind(df, mat)
w <- sapply(df_temp[,-c(1:3)], function(x) as.integer(x*1000))
# define a two-column matrix of coordinates to identify each cell in the lattice grid.
cc <- df_temp[,c("x","y")]
simout <- dynamAedes.m(species="albopictus",
scale="rg",
jhwv=habitat_liters,
temps.matrix=w[,as.numeric(format(as.Date(str),"%j")):as.numeric(format(as.Date(endr),"%j"))],
coords.proj4=utm32N,
cells.coords=as.matrix(cc),
startd=str,
endd=endr,
n.clusters=cl,
iter=it,
intro.eggs=ie,
compressed.output=FALSE,
seeding=TRUE,
verbose=FALSE)
summary(simout)
# Retrieve the maximum number of simulated days
dd <- max(simout)
# Compute the inter-quartile of abundances along the iterations
breaks=c(0.25,0.50,0.75)
ed=1:dd
adci(simout, eval_date=ed, breaks=breaks,
stage="Adults",
sub_stage = "Host-seeking", type="N")
# Compute the median of the iterations
breaks=c(0.50)
# Compute a raster with the  median of the iterations
breaks=c(0.50)
hs.r <- adci(simout, eval_date=ed, breaks=breaks,
stage="Adults",
sub_stage = "Host-seeking", type="N")
hs.r
hs.r$`Host-seeking_q_0.5`
plot(hs.r$`Host-seeking_q_0.5`$day30)
hs.r <- adci(simout, eval_date=ed, breaks=breaks,
stage="Adults",
sub_stage = "Host-seeking", type="O")
hs.r
names(hs.r)
View(hs.r)
dim(hs.r)
debugonce(adci)
adci(simout, eval_date=ed, breaks=breaks,
stage="Adults",
sub_stage = "Host-seeking", type="O")
adci(simout, eval_date=30, breaks=breaks,
stage="Adults",
sub_stage = "Host-seeking", type="O")
pippo <-adci(simout, eval_date=30, breaks=breaks,
stage="Adults",
sub_stage = "Host-seeking", type="O")
pippo
pippo <-adci(simout, eval_date=1, breaks=breaks,
stage="Adults",
sub_stage = "Host-seeking", type="O")
pippo
pippo <-adci(simout, eval_date=10, breaks=breaks,
stage="Adults",
sub_stage = "Host-seeking", type="O")
pippo
pippo <-adci(simout, eval_date=10, breaks=breaks,
stage="Adults",
type="O")
pippo
ed <- 1:dd
hs.r <- adci(simout, eval_date=ed, breaks=breaks,
stage="Adults",
sub_stage = "Host-seeking", type="N")
hs.r <- adci(simout, eval_date=ed, breaks=breaks,
stage="Adults",
sub_stage = "Host-seeking", type="N")
hs.r$`Host-seeking_q_0.5`
plot(hs.r$`Host-seeking_q_0.5`$day30)
plot(hs.r$`Host-seeking_q_0.5`$day29)
plot(hs.r$`Host-seeking_q_0.5`$day5)
plot(hs.r$`Host-seeking_q_0.5`$day7)
plot(hs.r$`Host-seeking_q_0.5`$day10)
plot(hs.r$`Host-seeking_q_0.5`$day8)
r1 <- raster(matrix(1:12, nrow = 3))
r1
library(raster)
r1 <- raster(matrix(1:12, nrow = 3))
r1
x <- crop(r1, extent(0,ncol(r1),0,nrow(r1)))
x
plotRGB(x)
?plotRGB
raster::plotRGB(x)
library(raster)
r1 <- raster(matrix(1:12, nrow = 3))
r1
x <- crop(r1, extent(0,ncol(r1),0,nrow(r1)))
raster::plotRGB(x)
plot(x)
x1 <- 0:ncol(x)
y1 <- 0:nrow(x)
z <- matrix(1, nrow=length(x1), ncol=length(y1))
col.mat <- t(apply(matrix(rgb(getValues(x)/255), nrow=nrow(x), byrow=TRUE), 2, rev))
# Rotate 45 degrees
persp(x1, y1, z, zlim=c(0,2), theta = 20, phi = 90,
col = col.mat, scale=FALSE, border=NA, box=FALSE)
col.mat <- t(apply(matrix(rgb(values(x)/255), nrow=nrow(x), byrow=TRUE), 2, rev))
col.mat <- t(apply(matrix((values(x)/255), nrow=nrow(x), byrow=TRUE), 2, rev))
col.mat
# Rotate 45 degrees
persp(x1, y1, z, zlim=c(0,2), theta = 20, phi = 90,
col = col.mat, scale=FALSE, border=NA, box=FALSE)
persp(x1, y1, z, zlim=c(0,2), theta = 20, phi = 90,
col = col.mat, scale=FALSE, border=NA, box=FALSE)
persp(x1, y1, z, zlim=c(0,2), theta = 20, phi = 90,
col = col.mat, scale=FALSE, border=NA, box=FALSE)
y1
rotation <- function(df, degree) {
dfr <- df
degree <- pi * degree / 180
l <- sqrt(df$start1^2 + df$start2^2)
teta <- atan(df$start2 / df$start1)
dfr$start1 <- round(l * cos(teta - degree))
dfr$start2 <- round(l * sin(teta - degree))
return(dfr)
}
test <- data.frame(start1=c(1,1,1,1,2,2,2,3,3,4),
start2=c(1,2,3,4,2,3,4,3,4,4),
logFC=c(5,5,1,0,8,0,5,2,4,3))
ggplot(test, aes(start1, start2)) +
geom_tile(aes(fill = logFC), colour = "gray", size=0.05) +
scale_fill_gradientn(colours=c("#0000FF","white","#FF0000"), na.value="#DAD7D3")
library(ggplot2)
test <- data.frame(start1=c(1,1,1,1,2,2,2,3,3,4),
start2=c(1,2,3,4,2,3,4,3,4,4),
logFC=c(5,5,1,0,8,0,5,2,4,3))
ggplot(test, aes(start1, start2)) +
geom_tile(aes(fill = logFC), colour = "gray", size=0.05) +
scale_fill_gradientn(colours=c("#0000FF","white","#FF0000"), na.value="#DAD7D3")
rotation <- function(df, degree) {
dfr <- df
degree <- pi * degree / 180
l <- sqrt(df$start1^2 + df$start2^2)
teta <- atan(df$start2 / df$start1)
dfr$start1 <- round(l * cos(teta - degree))
dfr$start2 <- round(l * sin(teta - degree))
return(dfr)
}
test2 <- rotation(test, -90)
ggplot(test2, aes(start1, start2)) +
geom_tile(aes(fill = logFC), colour = "gray", size=0.05) +
scale_fill_gradientn(colours=c("#0000FF","white","#FF0000"), na.value="#DAD7D3")
test2
r1
as.data.frame(r1, xy=TRUE)
r1.df<-as.data.frame(r1, xy=TRUE)
rotation <- function(df, degree) {
dfr <- df
degree <- pi * degree / 180
l <- sqrt(df$[,1]^2 + df$[,2]^2)
rotation <- function(df, degree) {
dfr <- df
degree <- pi * degree / 180
l <- sqrt(df[,1]^2 + df[,2]^2)
teta <- atan(df[,2] / df[,1])
dfr[,1] <- round(l * cos(teta - degree))
dfr[,2] <- round(l * sin(teta - degree))
return(dfr)
}
test2 <- rotation(test, -90)
ggplot(test2, aes(start1, start2)) +
geom_tile(aes(fill = logFC), colour = "gray", size=0.05) +
scale_fill_gradientn(colours=c("#0000FF","white","#FF0000"), na.value="#DAD7D3")
r1.df<-as.data.frame(r1, xy=TRUE)
ggplot(r1.df, aes(x, y)) +
geom_tile(aes(fill = layer), colour = "gray", size=0.05) +
scale_fill_gradientn(colours=c("#0000FF","white","#FF0000"), na.value="#DAD7D3")
ggplot(rotation(r1.df, -90), aes(x, y)) +
geom_tile(aes(fill = layer), colour = "gray", size=0.05) +
scale_fill_gradientn(colours=c("#0000FF","white","#FF0000"), na.value="#DAD7D3")
rotation(r1.df, -90)
rotation(r1.df, -90)
r1.df
setwd("GitHub/USE/")
knitr::opts_chunk$set(echo = TRUE)
envData <- USE::Worldclim_tmp
envData<-rast(envData,  type="xyz")
envData<-terra::rast(envData,  type="xyz")
library(terra)
rastPCA <- function (env.rast, nPC=NULL, naMask=TRUE, stand=FALSE){
#' Principal Component Analysis for Rasters
#'
#' The \code{rastPCA} function calculates the principal component analysis  (PCA) for SpatRaster, RasterBrick, or RasterStack objects and returns a SpatRaster with multiple layers representing the PCA components. Internally, \code{rastPCA} utilizes the \link[stats]{princomp} function for R-mode PCA analysis. The covariance matrix is computed using all the observations within the provided SpatRaster object, which describes the environmental conditions.
#' The covariance matrix obtained is subsequently utilized as input for the \code{princomp} function, which conducts the PCA. The resulting PCA components are then used to generate the final SpatRaster, consisting of multiple layers that represent the PCA components.
#'
#' Pixels with missing values in one or more bands will be set to NA. The built-in check for such pixels can lead to a slow-down of rastPCA.
#' However, if you make sure or know beforehand that all pixels have either only valid values or only NAs throughout all layers you can disable this check
#' by setting \code{naMask=FALSE} which speeds up the computation.
#'
#' Standardized PCA (\code{stand=TRUE}) can be useful if imagery or bands of different dynamic ranges are combined. In this case, the correlation matrix is computed instead of the covariance matrix, which
#' has the same effect as using normalised bands of unit variance.
#'
#' @param env.rast  A RasterStack, RasterBrick or a SpatRaster object comprising the variables describing the environmental space.
#' @param nPC Integer. Number of PCA components to return.
#' @param stand Logical. If \code{TRUE}, perform standardized PCA. Corresponds to centered and scaled input image. This is usually beneficial for equal weighting of all layers. (\code{FALSE} by default)
#' @param naMask Logical. Masks all pixels which have at least one NA (default \code{TRUE} is recommended but introduces a slow-down.
#' @seealso The \code{rastPCA} function has been conceptualized starting from \code{RStoolbox::rasterPCA} (\url{https://github.com/bleutner/RStoolbox}).
#' @return Returns a named list containing the PCA model object ($pca) and the SpatRaster with the principal component layers ($PCs).
#' @export
rastPCA <- function (env.rast, nPC=NULL, naMask=TRUE, stand=FALSE){
if (inherits(env.rast, "BasicRaster")) {
env.rast <- terra::rast(env.rast)
}
if (terra::nlyr(env.rast) <= 1) {
stop("At least two layers are needed to calculate PCA")
}
if(is.null(nPC)){
nPC <- terra::nlyr(env.rast)
}
if (nPC > terra::nlyr(env.rast)) {
nPC <- terra::nlyr(env.rast)
message(paste0( "\nThe maximum number of PCs that can be estimated is ", terra::nlyr(env.rast),'\n'))
}
if (sum(terra::global(env.rast, fun="isNA"))==sum(terra::global(env.rast,fun=function(x) terra::ncell(x)))) {
stop("The layers are empty or contain only NAs")}
if (naMask==TRUE) {
# maskNA <- is.na(env.rast[[1]])
maskNA <-!sum(terra::app(env.rast, is.na))
env.rast <- terra::mask(env.rast, maskNA, maskvalue = NA)
}
covMatrix <- terra::layerCor(env.rast, fun = "cov", na.rm = TRUE)
eigenDecomp <- princompCustom(covmat = covMatrix[[1]], cor = stand)
eigenDecomp$center <- covMatrix$mean
eigenDecomp$n.obs <- nrow(as.data.frame(env.rast[[1]]))
if (stand==TRUE) {
S <- diag(covMatrix$covariance)
eigenDecomp$scale <- sqrt(S * (eigenDecomp$n.obs - 1)/eigenDecomp$n.obs)
}
pci <- terra::predict(env.rast, eigenDecomp, nPC=nPC, fun=pca_predict)
names(pci) <- paste0("PC", 1:nPC)
return(list(call = match.call(), pca = eigenDecomp, PCs = pci))
}
debugonce(rastPCA)
pippo<-rastPCA(env.rast=envData, nPC=2, naMask=TRUE, stand=TRUE)
maskNA
plot(maskNA)
#' Custom version of princomp
#' The warning() at L53 substitutes the stop() in the original version of "princomp".
#' @param formula a formula with no response variable, referring only to numeric variables.
#' @param data an optional data frame (or similar: see model.frame) containing the variables in the formula formula. By default the variables are taken from environment(formula).
#' @param subset an optional vector used to select rows (observations) of the data matrix x.
#' @param na.action a function which indicates what should happen when the data contain NAs. The default is set by the na.action setting of options, and is na.fail if that is unset. The ‘factory-fresh’ default is na.omit.
#' @param x a numeric matrix or data frame which provides the data for the principal components analysis.
#' @param cor a logical value indicating whether the calculation should use the correlation matrix or the covariance matrix. (The correlation matrix can only be used if there are no constant variables.)
#' @param scores a logical value indicating whether the score on each principal component should be calculated.
#' @param covmat a covariance matrix, or a covariance list as returned by cov.wt (and cov.mve or cov.mcd from package MASS). If supplied, this is used rather than the covariance matrix of x.
#' @param fix_sign Should the signs of the loadings and scores be chosen so that the first element of each loading is non-negative?
#' @param object Object of class inheriting from "princomp".
#' @param newdata An optional data frame or matrix in which to look for variables with which to predict. If omitted, the scores are used. If the original fit used a formula or a data frame or a matrix with column names, newdata must contain columns with the same names. Otherwise it must contain the same number of columns, to be used in the same order.
#' @importFrom stats cov.wt setNames
#' @keywords internal
#' @NoRd
princompCustom <- function (x, cor = FALSE, scores = TRUE, covmat = NULL, subset = rep_len(TRUE, nrow(as.matrix(x))), fix_sign = TRUE, ...) {
chkDots(...)
cl <- match.call()
cl[[1L]] <- as.name("princomp")
z <- if (!missing(x))
as.matrix(x)[subset, , drop = FALSE]
if (is.list(covmat)) {
if (anyNA(match(c("cov", "n.obs"), names(covmat))))
stop("'covmat' is not a valid covariance list")
cv <- covmat$cov
n.obs <- covmat$n.obs
cen <- covmat$center
}
else if (is.matrix(covmat)) {
if (!missing(x))
warning("both 'x' and 'covmat' were supplied: 'x' will be ignored")
cv <- covmat
n.obs <- NA
cen <- NULL
}
else if (is.null(covmat)) {
dn <- dim(z)
if (dn[1L] < dn[2L])
stop("'princomp' can only be used with more units than variables")
covmat <- stats::cov.wt(z)
n.obs <- covmat$n.obs
cv <- covmat$cov * (1 - 1/n.obs)
cen <- covmat$center
}
else stop("'covmat' is of unknown type")
if (!is.numeric(cv))
stop("PCA applies only to numerical variables")
if (cor) {
sds <- sqrt(diag(cv))
if (any(sds == 0))
stop("cannot use 'cor = TRUE' with a constant variable")
cv <- cv/(sds %o% sds)
}
edc <- eigen(cv, symmetric = TRUE)
ev <- edc$values
if (any(neg <- ev < 0)) {
if (any(ev[neg] < -9 * .Machine$double.eps * ev[1L]))
warning("covariance matrix is not non-negative definite")
else ev[neg] <- 0
}
cn <- paste0("Comp.", 1L:ncol(cv))
names(ev) <- cn
dimnames(edc$vectors) <- if (missing(x))
list(dimnames(cv)[[2L]], cn)
else list(dimnames(x)[[2L]], cn)
sdev <- sqrt(ev)
sc <- stats::setNames(if (cor)
sds
else rep.int(1, ncol(cv)), colnames(cv))
fix <- if (fix_sign)
function(A) {
mysign <- function(x) ifelse(x < 0, -1, 1)
A[] <- apply(A, 2L, function(x) x * mysign(x[1L]))
A
}
else identity
ev <- fix(edc$vectors)
scr <- if (scores && !missing(x) && !is.null(cen))
scale(z, center = cen, scale = sc) %*% ev
if (is.null(cen))
cen <- rep(NA_real_, nrow(cv))
edc <- list(sdev = sdev, loadings = structure(ev, class = "loadings"),
center = cen, scale = sc, n.obs = n.obs, scores = scr,
call = cl)
class(edc) <- "princomp"
edc
}
pca_predict <- function (data, model, nPC)
{
predict(data, model)[, 1:nPC]
}
rastPCA <- function (env.rast, nPC = NULL, naMask = TRUE, stand = FALSE)
{
if (inherits(env.rast, "BasicRaster")) {
env.rast <- terra::rast(env.rast)
}
if (terra::nlyr(env.rast) <= 1) {
stop("At least two layers are needed to calculate PCA")
}
if (is.null(nPC)) {
nPC <- terra::nlyr(env.rast)
}
if (nPC > terra::nlyr(env.rast)) {
nPC <- terra::nlyr(env.rast)
message(paste0("\nThe maximum number of PCs that can be estimated is ",
terra::nlyr(env.rast), "\n"))
}
if (sum(terra::global(env.rast, fun = "isNA")) == sum(terra::global(env.rast,
fun = function(x) terra::ncell(x)))) {
stop("The layers are empty or contain only NAs")
}
if (naMask == TRUE) {
maskNA <- !sum(terra::app(env.rast, is.na))
env.rast <- terra::mask(env.rast, maskNA, maskvalue = FALSE)
}
covMatrix <- terra::layerCor(env.rast, fun = "cov", na.rm = TRUE)
eigenDecomp <- princompCustom(covmat = covMatrix$covariance, cor = stand)
eigenDecomp$center <- covMatrix$mean
eigenDecomp$n.obs <- nrow(as.data.frame(env.rast[[1]]))
if (stand == TRUE) {
S <- diag(covMatrix$covariance)
eigenDecomp$scale <- sqrt(S * (eigenDecomp$n.obs - 1)/eigenDecomp$n.obs)
}
pci <- terra::predict(env.rast, eigenDecomp, nPC = nPC, fun = pca_predict)
names(pci) <- paste0("PC", 1:nPC)
return(list(call = match.call(), pca = eigenDecomp, PCs = pci))
}
pippo<-rastPCA(env.rast=envData, nPC=2, naMask=TRUE, stand=TRUE)
pippo
class(pippo)
#' Principal Component Analysis for Rasters
#'
#' The \code{rastPCA} function calculates the principal component analysis  (PCA) for SpatRaster, RasterBrick, or RasterStack objects and returns a SpatRaster with multiple layers representing the PCA components. Internally, \code{rastPCA} utilizes the \link[stats]{princomp} function for R-mode PCA analysis. The covariance matrix is computed using all the observations within the provided SpatRaster object, which describes the environmental conditions.
#' The covariance matrix obtained is subsequently utilized as input for the \code{princomp} function, which conducts the PCA. The resulting PCA components are then used to generate the final SpatRaster, consisting of multiple layers that represent the PCA components.
#'
#' Pixels with missing values in one or more bands will be set to NA. The built-in check for such pixels can lead to a slow-down of rastPCA.
#' However, if you make sure or know beforehand that all pixels have either only valid values or only NAs throughout all layers you can disable this check
#' by setting \code{naMask=FALSE} which speeds up the computation.
#'
#' Standardized PCA (\code{stand=TRUE}) can be useful if imagery or bands of different dynamic ranges are combined. In this case, the correlation matrix is computed instead of the covariance matrix, which
#' has the same effect as using normalised bands of unit variance.
#'
#' @param env.rast  A RasterStack, RasterBrick or a SpatRaster object comprising the variables describing the environmental space.
#' @param nPC Integer. Number of PCA components to return.
#' @param stand Logical. If \code{TRUE}, perform standardized PCA. Corresponds to centered and scaled input image. This is usually beneficial for equal weighting of all layers. (\code{FALSE} by default)
#' @param naMask Logical. Masks all pixels which have at least one NA (default \code{TRUE} is recommended but introduces a slow-down.
#' @seealso The \code{rastPCA} function has been conceptualized starting from \code{RStoolbox::rasterPCA} (\url{https://github.com/bleutner/RStoolbox}).
#' @return Returns a named list containing the PCA model object ($pca) and the SpatRaster with the principal component layers ($PCs).
#' @export
rastPCA <- function (env.rast, nPC=NULL, naMask=TRUE, stand=FALSE){
if (inherits(env.rast, "BasicRaster")) {
env.rast <- terra::rast(env.rast)
}
if (terra::nlyr(env.rast) <= 1) {
stop("At least two layers are needed to calculate PCA")
}
if(is.null(nPC)){
nPC <- terra::nlyr(env.rast)
}
if (nPC > terra::nlyr(env.rast)) {
nPC <- terra::nlyr(env.rast)
message(paste0( "\nThe maximum number of PCs that can be estimated is ", terra::nlyr(env.rast),'\n'))
}
if (sum(terra::global(env.rast, fun="isNA"))==sum(terra::global(env.rast,fun=function(x) terra::ncell(x)))) {
stop("The layers are empty or contain only NAs")}
if (naMask==TRUE) {
# maskNA <- is.na(env.rast[[1]])
maskNA <-!sum(terra::app(env.rast, is.na))
env.rast <- terra::mask(env.rast, maskNA, maskvalue = NA)
}
covMatrix <- terra::layerCor(env.rast, fun = "cov", na.rm = TRUE)
eigenDecomp <- princompCustom(covmat = covMatrix[[1]], cor = stand)
eigenDecomp$center <- covMatrix$mean
eigenDecomp$n.obs  <- global(!any(is.na(env.rast)), sum)$sum
# eigenDecomp$n.obs <- nrow(as.data.frame(env.rast[[1]]))
if (stand==TRUE) {
S <- diag(covMatrix$covariance)
eigenDecomp$scale <- sqrt(S * (eigenDecomp$n.obs - 1)/eigenDecomp$n.obs)
}
pci <- terra::predict(env.rast, eigenDecomp, nPC=nPC, fun=pca_predict)
names(pci) <- paste0("PC", 1:nPC)
return(list(call = match.call(), pca = eigenDecomp, PCs = pci))
}
debugonce(rastPCA)
pippo<-rastPCA(env.rast=envData, nPC=2, naMask=TRUE, stand=TRUE)
n.obs <- nrow(as.data.frame(env.rast[[1]]))
eigenDecomp$n.obs
n.obs
#------USE-----------------
setwd("/home/daniele/GitHub/USE/")
# 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
# token
library(devtools)
library(roxygen2)
# library(usethat)
# devtools::create("yourPkg")
# devtools::install_github("mattmar/dynamAedes")
devtools::load_all(".") # Working directory should be in the package directory
#update documentation
devtools::document()
#check everything is ok for the CRAN
devtools::check()#vignettes=FALSE
# library(usethat)
# devtools::create("yourPkg")
# devtools::install_github("mattmar/dynamAedes")
devtools::load_all(".") # Working directory should be in the package directory
#update documentation
devtools::document()
#check everything is ok for the CRAN
devtools::check()#vignettes=FALSE
#install package
remove.packages("USE")
devtools::install(".")
#website
# devtools::install_github('r-lib/pkgdown')
library(pkgdown)
# update rmd
knitr::knit("README.Rmd")
# Run to build the website
pkgdown::build_site("/home/ddare/GitHub/USE/", install = FALSE,
examples = FALSE)
# Run to build the website
pkgdown::build_site("/home/ddare/GitHub/USE/", install = FALSE,
examples = FALSE)
# Run to build the website
pkgdown::build_site("/home/daniele/GitHub/USE/", install = FALSE,
examples = FALSE)
