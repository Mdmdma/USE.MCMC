test.percent=percTesting,
n=Nreps,
parallelSettings=list("parallel", ncore=myCores))
#inspect the model
m1
m1@models$Observed$glm$`1`@evaluation$test.dep@predicted
m1@models$Observed$glm$`1`@evaluation$test.dep@statistics$COR
glm_out <- rbind(c("GLM",
mean(unlist(lapply(m1@models$Observed$glm, function(x){ mean(x@evaluation$test.dep@statistics$AUC) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){ mean(x@evaluation$test.dep@statistics$COR[1]) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){ mean(x@evaluation$test.dep@statistics$Deviance) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){ mean(x@evaluation$test.dep@threshold_based$TSS[2]) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){ mean(x@evaluation$test.dep@threshold_based$Kappa[2]) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){ mean(x@evaluation$test.dep@threshold_based$sensitivity[2]) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){ mean(x@evaluation$test.dep@threshold_based$specificity[2]) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){ mean(ecospat.boyce(fit =  x@evaluation$test.dep@predicted,
obs=   x@evaluation$test.dep@predicted[which(x@evaluation$test.dep@observed==1)],
nclass=0,
window.w="default", res=100, PEplot = FALSE)$Spearman.cor)
})), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){Metrics::rmse(x@evaluation$test.dep@observed,x@evaluation$test.dep@predicted)})), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){Dsquared(x@object,adjust = TRUE)})), na.rm=T)))
#store info of the models statistics: this is a bit messy, might be useful to write a function for this
tmp_out=setNames(data.frame(matrix(ncol = 11, nrow = 0)), c("ModelType", "AUC", "COR", "Deviance", "TSS",
"Kappa","Sensitivity", "Specificity", "BoyceI", 'RMSE',"R2"   ))
tmp_out
tmp_out
glm_out <- rbind(c("GLM",
mean(unlist(lapply(m1@models$Observed$glm, function(x){ mean(x@evaluation$test.dep@statistics$AUC) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){ mean(x@evaluation$test.dep@statistics$COR[1]) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){ mean(x@evaluation$test.dep@statistics$Deviance) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){ mean(x@evaluation$test.dep@threshold_based$TSS[2]) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){ mean(x@evaluation$test.dep@threshold_based$Kappa[2]) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){ mean(x@evaluation$test.dep@threshold_based$sensitivity[2]) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){ mean(x@evaluation$test.dep@threshold_based$specificity[2]) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){ mean(ecospat.boyce(fit = x@evaluation$test.dep@predicted,
obs=x@evaluation$test.dep@predicted[which(x@evaluation$test.dep@observed==1)],
nclass=0,
window.w="default", res=100, PEplot = FALSE)$Spearman.cor)
})), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){Metrics::rmse(x@evaluation$test.dep@observed,x@evaluation$test.dep@predicted)})), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){Dsquared(x@object,adjust = TRUE)})), na.rm=T)))
library(ecospat)
glm_out <- rbind(c("GLM",
mean(unlist(lapply(m1@models$Observed$glm, function(x){ mean(x@evaluation$test.dep@statistics$AUC) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){ mean(x@evaluation$test.dep@statistics$COR[1]) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){ mean(x@evaluation$test.dep@statistics$Deviance) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){ mean(x@evaluation$test.dep@threshold_based$TSS[2]) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){ mean(x@evaluation$test.dep@threshold_based$Kappa[2]) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){ mean(x@evaluation$test.dep@threshold_based$sensitivity[2]) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){ mean(x@evaluation$test.dep@threshold_based$specificity[2]) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){ mean(ecospat::ecospat.boyce(fit = x@evaluation$test.dep@predicted,
obs=x@evaluation$test.dep@predicted[which(x@evaluation$test.dep@observed==1)],
nclass=0,
window.w="default", res=100, PEplot = FALSE)$Spearman.cor)
})), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){Metrics::rmse(x@evaluation$test.dep@observed,x@evaluation$test.dep@predicted)})), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){Dsquared(x@object,adjust = TRUE)})), na.rm=T)))
glm_out <- rbind(c("GLM",
mean(unlist(lapply(m1@models$Observed$glm, function(x){ mean(x@evaluation$test.dep@statistics$AUC) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){ mean(x@evaluation$test.dep@statistics$COR[1]) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){ mean(x@evaluation$test.dep@statistics$Deviance) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){ mean(x@evaluation$test.dep@threshold_based$TSS[2]) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){ mean(x@evaluation$test.dep@threshold_based$Kappa[2]) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){ mean(x@evaluation$test.dep@threshold_based$sensitivity[2]) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){ mean(x@evaluation$test.dep@threshold_based$specificity[2]) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){ mean(ecospat::ecospat.boyce(fit = x@evaluation$test.dep@predicted,
obs=x@evaluation$test.dep@predicted[which(x@evaluation$test.dep@observed==1)],
nclass=0,
window.w="default", res=100, PEplot = FALSE)$cor)
})), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){Metrics::rmse(x@evaluation$test.dep@observed,x@evaluation$test.dep@predicted)})), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){Dsquared(x@object,adjust = TRUE)})), na.rm=T)))
#inspect the structure of the sdm model object
m1@models$Observed$glm$`1`@evaluation$test.dep@observed
modEvA::RsqGLM(obs=m1@models$Observed$glm$`1`@evaluation$test.dep@observed, pred=m1@models$Observed$glm$`1`@evaluation$test.dep@predicted)
modEvA::RsqGLM(obs=m1@models$Observed$glm$`1`@evaluation$test.dep@observed, pred=m1@models$Observed$glm$`1`@evaluation$test.dep@predicted)$Nagelkerke
modEvA::RsqGLM(obs=m1@models$Observed$glm$`1`@evaluation$test.dep@observed, pred=m1@models$Observed$glm$`1`@evaluation$test.dep@predicted, plot=FALSE)$Nagelkerke
glm_out <- rbind(c("GLM",
mean(unlist(lapply(m1@models$Observed$glm, function(x){ mean(x@evaluation$test.dep@statistics$AUC) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){ mean(x@evaluation$test.dep@statistics$COR[1]) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){ mean(x@evaluation$test.dep@statistics$Deviance) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){ mean(x@evaluation$test.dep@threshold_based$TSS[2]) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){ mean(x@evaluation$test.dep@threshold_based$Kappa[2]) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){ mean(x@evaluation$test.dep@threshold_based$sensitivity[2]) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){ mean(x@evaluation$test.dep@threshold_based$specificity[2]) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){ mean(ecospat::ecospat.boyce(fit = x@evaluation$test.dep@predicted,
obs=x@evaluation$test.dep@predicted[which(x@evaluation$test.dep@observed==1)],
nclass=0,
window.w="default", res=100, PEplot = FALSE)$cor)
})), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){Metrics::rmse(x@evaluation$test.dep@observed,x@evaluation$test.dep@predicted)})), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){modEvA::RsqGLM(obs=x@evaluation$test.dep@observed,
pred=x@evaluation$test.dep@predicted,
plot=FALSE)$Nagelkerke})), na.rm=T)))# (pseudo) R-squared
glm_out
rbind(tmp_out, glm_rows)
rbind(tmp_out, glm_out)
head(tmp_out)
tmp_out[1,]<-glm_out
tmp_out
rf_out <- rbind(c("RF",
mean(unlist(lapply(m1@models$Observed$rf, function(x){ mean(x@evaluation$test.dep@statistics$AUC) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$rf, function(x){ mean(x@evaluation$test.dep@statistics$COR[1]) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$rf, function(x){ mean(x@evaluation$test.dep@statistics$Deviance) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$rf, function(x){ mean(x@evaluation$test.dep@threshold_based$TSS[2]) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$rf, function(x){ mean(x@evaluation$test.dep@threshold_based$Kappa[2]) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$rf, function(x){ mean(x@evaluation$test.dep@threshold_based$sensitivity[2]) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$rf, function(x){ mean(x@evaluation$test.dep@threshold_based$specificity[2]) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$rf, function(x){ mean(ecospat::ecospat.boyce(fit = x@evaluation$test.dep@predicted,
obs=x@evaluation$test.dep@predicted[which(x@evaluation$test.dep@observed==1)],
nclass=0,
window.w="default", res=100, PEplot = FALSE)$cor)
})), na.rm=T),
mean(unlist(lapply(m1@models$Observed$rf, function(x){Metrics::rmse(x@evaluation$test.dep@observed,x@evaluation$test.dep@predicted)})), na.rm=T),
mean(unlist(lapply(m1@models$Observed$rf, function(x){modEvA::RsqGLM(obs=x@evaluation$test.dep@observed,
pred=x@evaluation$test.dep@predicted,
plot=FALSE)$Nagelkerke})), na.rm=T)))# (pseudo) R-squared
rf_out <- rbind(c("RF",
mean(unlist(lapply(m1@models$Observed$rf, function(x){ mean(x@evaluation$test.dep@statistics$AUC) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$rf, function(x){ mean(x@evaluation$test.dep@statistics$COR[1]) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$rf, function(x){ mean(x@evaluation$test.dep@statistics$Deviance) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$rf, function(x){ mean(x@evaluation$test.dep@threshold_based$TSS[2]) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$rf, function(x){ mean(x@evaluation$test.dep@threshold_based$Kappa[2]) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$rf, function(x){ mean(x@evaluation$test.dep@threshold_based$sensitivity[2]) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$rf, function(x){ mean(x@evaluation$test.dep@threshold_based$specificity[2]) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$rf, function(x){ mean(ecospat::ecospat.boyce(fit = x@evaluation$test.dep@predicted,
obs=x@evaluation$test.dep@predicted[which(x@evaluation$test.dep@observed==1)],
nclass=0,
window.w="default", res=100, PEplot = FALSE)$cor)
})), na.rm=T),
mean(unlist(lapply(m1@models$Observed$rf, function(x){Metrics::rmse(x@evaluation$test.dep@observed,x@evaluation$test.dep@predicted)})), na.rm=T),
mean(unlist(lapply(m1@models$Observed$rf, function(x){mean(x@object$rsq)})), na.rm=T)))# (pseudo) R-squared
rf_out
tmp_out[2,]<-rf_out
tmp_out
round(tmp_out,3)
rapply(object = tmp_out, f = round, classes = "numeric", how = "replace", digits = 3)
rapply(object = tmp_out, f = round, classes = "numeric", how = "replace", digits = 0)
tmp_out %>%
dplyr::mutate_if(is.numeric, round)
tmp_out %>%
dplyr::mutate_if(is.numeric, round)
sapply(tmp_out, as.numeric)
sapply(tmp_out[2:ncol(tmp_out)], as.numeric)
tmp_out<-sapply(tmp_out[2:ncol(tmp_out)], as.numeric)
tmp_out<-sapply(tmp_out, function(x){round(x,3)})
tmp_out
tmp_out[1,]<-glm_out
tmp_out[2,]<-rf_out
#compute spatial predictions and rmse
m1.preds <- predict(m1, newdata=envData, overwrite=TRUE)
rmse.distribution <- apply(m1.preds[,2:ncol(m1.preds)], 2, function(x){round(Metrics::rmse(m1.preds$layer,x),3)})
m1.preds
m1.preds <- na.omit(raster::as.data.frame(raster::stack(new.pres$suitab.raster, m1.preds)))
m1.preds
#compute spatial predictions and rmse
m1.preds <- predict(m1, newdata=envData, overwrite=TRUE)
m1.preds <- na.omit(raster::as.data.frame(raster::stack(new.pres$suitab.raster, m1.preds)))
rmse.distribution <- apply(m1.preds[,2:ncol(m1.preds)], 2, function(x){round(Metrics::rmse(m1.preds$layer,x),3)})
cor.distribution <- apply(m1.preds[,2:ncol(m1.preds)], 2, function(x){round(cor(m1.preds$layer,x),3)})
rmse.distribution <- data.frame(ModelType=attributes(rmse.distribution)$names,
rmse.distribution=rmse.distribution,
cor.distribution=cor.distribution)
rmse.distribution$ModelType <- gsub(sapply(rmse.distribution$ModelType, function(x){strsplit(x, "_")[[1]][[4]]}),
pattern=".re", replacement = "")
rmse.distribution <- rmse.distribution %>%
group_by(ModelType) %>%
summarise(rmse.distribution=mean(rmse.distribution, na.rm=TRUE),
cor.distribution=mean(cor.distribution, na.rm=TRUE)) %>%
mutate(ModelType=toupper(ModelType))
rmse.distribution
#compute spatial predictions and rmse
m1.preds <- predict(m1, newdata=envData, overwrite=TRUE)
#compute spatial predictions and rmse
m1.Allpreds <- predict(m1, newdata=envData, overwrite=TRUE)
names(m1.Allpreds)
my.parameters <- formatFunctions(bio1 = c(fun = 'dnorm', mean = 100, sd = 400),
bio12 = c(fun = 'dnorm', mean = 2000, sd = 4000))
my.first.species <- generateSpFromFun(raster.stack = envData[[c("bio1", "bio12")]],
parameters = my.parameters,
plot = FALSE)
plot(my.first.species$suitab.raster, main = "Virtual tree \n climatic suitability")
#reclassify suitability raster using a probability conversion rule
new.pres<-convertToPA(x=my.first.species,
beta="random",
alpha = -0.05, plot = FALSE ,
species.prevalence = 0.1) # play with the species geographic prevalence
plot(new.pres)
# Sample occurrences
presence.points <- sampleOccurrences(new.pres,
n = 500, # The number of points to sample
type = "presence-absence",
correct.by.suitability = TRUE,
plot = TRUE)
myPres <- presence.points$sample.points[, c( "x", "y",  "Observed")]
myPres <- sf::st_as_sf(myPres, coords=c("x", "y"), crs=4326)
myPres <- sf::as_Spatial(myPres)
#reclassify suitability raster using a probability conversion rule
new.pres<-convertToPA(x=my.first.species,
beta="random",
alpha = -0.05, plot = FALSE ,
species.prevalence = 0.4) # play with the species geographic prevalence
plot(new.pres)
# Sample occurrences
presence.points <- sampleOccurrences(new.pres,
n = 500, # The number of points to sample
type = "presence-absence",
correct.by.suitability = TRUE,
plot = TRUE)
myPres <- presence.points$sample.points[, c( "x", "y",  "Observed")]
myPres <- sf::st_as_sf(myPres, coords=c("x", "y"), crs=4326)
myPres <- sf::as_Spatial(myPres)
#inspect the model
m1
#inspect the structure of the sdm model object
m1@models$Observed$glm$`1`@evaluation$test.dep@observed
m1@models$Observed$glm$`1`@evaluation$test.dep@statistics$COR
#store info of the models statistics: this is a bit messy, might be useful to write a function for this
tmp_out <- setNames(data.frame(matrix(ncol = 11, nrow = 0)), c("ModelType", "AUC", "COR", "Deviance", "TSS",
"Kappa","Sensitivity", "Specificity", "CBI", 'RMSE',"R2"   ))
glm_out <- rbind(c("GLM",
mean(unlist(lapply(m1@models$Observed$glm, function(x){ mean(x@evaluation$test.dep@statistics$AUC) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){ mean(x@evaluation$test.dep@statistics$COR[1]) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){ mean(x@evaluation$test.dep@statistics$Deviance) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){ mean(x@evaluation$test.dep@threshold_based$TSS[2]) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){ mean(x@evaluation$test.dep@threshold_based$Kappa[2]) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){ mean(x@evaluation$test.dep@threshold_based$sensitivity[2]) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){ mean(x@evaluation$test.dep@threshold_based$specificity[2]) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){ mean(ecospat::ecospat.boyce(fit = x@evaluation$test.dep@predicted,
obs=x@evaluation$test.dep@predicted[which(x@evaluation$test.dep@observed==1)],
nclass=0,
window.w="default", res=100, PEplot = FALSE)$cor)
})), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){Metrics::rmse(x@evaluation$test.dep@observed,x@evaluation$test.dep@predicted)})), na.rm=T),
mean(unlist(lapply(m1@models$Observed$glm, function(x){modEvA::RsqGLM(obs=x@evaluation$test.dep@observed,
pred=x@evaluation$test.dep@predicted,
plot=FALSE)$Nagelkerke})), na.rm=T)))# (pseudo) R-squared
rf_out <- rbind(c("RF",
mean(unlist(lapply(m1@models$Observed$rf, function(x){ mean(x@evaluation$test.dep@statistics$AUC) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$rf, function(x){ mean(x@evaluation$test.dep@statistics$COR[1]) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$rf, function(x){ mean(x@evaluation$test.dep@statistics$Deviance) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$rf, function(x){ mean(x@evaluation$test.dep@threshold_based$TSS[2]) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$rf, function(x){ mean(x@evaluation$test.dep@threshold_based$Kappa[2]) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$rf, function(x){ mean(x@evaluation$test.dep@threshold_based$sensitivity[2]) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$rf, function(x){ mean(x@evaluation$test.dep@threshold_based$specificity[2]) })), na.rm=T),
mean(unlist(lapply(m1@models$Observed$rf, function(x){ mean(ecospat::ecospat.boyce(fit = x@evaluation$test.dep@predicted,
obs=x@evaluation$test.dep@predicted[which(x@evaluation$test.dep@observed==1)],
nclass=0,
window.w="default", res=100, PEplot = FALSE)$cor)
})), na.rm=T),
mean(unlist(lapply(m1@models$Observed$rf, function(x){Metrics::rmse(x@evaluation$test.dep@observed,x@evaluation$test.dep@predicted)})), na.rm=T),
mean(unlist(lapply(m1@models$Observed$rf, function(x){mean(x@object$rsq)})), na.rm=T)))# (pseudo) R-squared
tmp_out[1,]<-glm_out
tmp_out[2,]<-rf_out
tmp_out
m1.Allpreds
names(m1.Allpreds)
names(m1.Allpreds)
# compute cor and rmse with the observed distribution
m1.preds <- na.omit(raster::as.data.frame(raster::stack(new.pres$suitab.raster, m1.Allpreds)))
rmse.distribution <- apply(m1.preds[,2:ncol(m1.preds)], 2, function(x){round(Metrics::rmse(m1.preds$layer,x),3)})
cor.distribution <- apply(m1.preds[,2:ncol(m1.preds)], 2, function(x){round(cor(m1.preds$layer,x),3)})
m1.preds
m1.preds
rmse.distribution <- apply(m1.preds[,2:ncol(m1.preds)], 2, function(x){round(Metrics::rmse(m1.preds$layer,x),3)})
cor.distribution <- apply(m1.preds[,2:ncol(m1.preds)], 2, function(x){round(cor(m1.preds$layer,x),3)})
rmse.distribution <- data.frame(ModelType=attributes(rmse.distribution)$names,
rmse.distribution=rmse.distribution,
cor.distribution=cor.distribution)
rmse.distribution$ModelType <- gsub(sapply(rmse.distribution$ModelType, function(x){strsplit(x, "_")[[1]][[4]]}),
pattern=".re", replacement = "")
rmse.distribution <- rmse.distribution %>%
group_by(ModelType) %>%
summarise(rmse.distribution=mean(rmse.distribution, na.rm=TRUE),
cor.distribution=mean(cor.distribution, na.rm=TRUE)) %>%
mutate(ModelType=toupper(ModelType))
rmse.distribution
glm.Meanpred <- raster::calc(m1.Allpreds[[1:5]], mean)
Meanpred <- raster::stack("GLM.mean"=raster::calc(m1.Allpreds[[1:5]], mean),
"RF.mean"=raster::calc(m1.Allpreds[[5:10]], mean))
Meanpred <- raster::stack(raster::calc(m1.Allpreds[[1:5]], mean),
raster::calc(m1.Allpreds[[5:10]], mean))
names(Meanpred)<-c("GLM.mean", "RF.mean")
plot(Meanpred)
plot(Meanpred)
plot(presence.points$original.distribution.raster)
plot(presence.points$original.distribution.raster)
Meanpred <- raster::stack(new.pres$probability.of.occurrence,
raster::calc(m1.Allpreds[[1:5]], mean),
raster::calc(m1.Allpreds[[5:10]], mean))
names(Meanpred)<-c("VS.propooc", "GLM.mean", "RF.mean")
plot(Meanpred)
getModelInfo(m1)
# We can generate the roc curve and compare the results for all models:
roc(m1)
#if you want to get directly the averaged predictions, then
p2m <- predict(m1, newdata=envData, overwrite=TRUE, mean=T)
p2m
plot(p2m)
# ensemble based on a Weighted averaging that is weighted using AUC statistic
e1 <- ensemble(mm1, newdata=envData, overwrite=TRUE, setting=list(method='weighted',stat='AUC'))
# ensemble based on a Weighted averaging that is weighted using AUC statistic
e1 <- ensemble(m1, newdata=envData, overwrite=TRUE, setting=list(method='weighted',stat='AUC'))
e1
plot(e1)
my.parameters
my.first.species
generateSpFromFun(raster.stack = envData[[c("bio1", "bio12")]],
parameters = my.parameters,
plot = FALSE)
generateSpFromFun(raster.stack = envData[[c("bio1", "bio12")]],
parameters = my.parameters,
plot = FALSE,
rescale.each.response = FALSE)
generateSpFromFun(raster.stack = envData[[c("bio1", "bio12")]],
parameters = my.parameters,
plot = TRUE,
rescale.each.response = FALSE)
generateSpFromFun(raster.stack = envData[[c("bio1", "bio12")]],
parameters = my.parameters,
plot = TRUE,
rescale.each.response = TRUE)
plotResponse
my.first.species
my.first.species$details
my.first.species$approach
my.first.species$details
my.first.species$details$parameters$bio1
my.first.species$details$parameters
my.first.species$details
myPres <- presence.points$sample.points[, c( "x", "y",  "Observed")]
myPres <- sf::st_as_sf(myPres, coords=c("x", "y"), crs=4326)
train.df<-terra::extract(envData, myPres)
train.df
train.df<-terra::extract(envData, myPres, df=TRUE)
head(train.df)
train.df<-cbind.data.frame(PA=myPres$Observed, train.df[,2:ncol(train.df)])
head(train.df)
cor(train.df)
GGally::ggcorr(cor(train.df), geom = "text")
GGally::ggcorr(cor(train.df), geom = "text")
Vars_to_remove <- caret::findCorrelation(cor(train.df), cutoff = .6, names = T)
Vars_to_remove
#variables to keep are:
paste0("bio", seq_len(19))[!paste0("bio", seq_len(19)) %in% Vars_to_remove]
#get rid of correlated variables from training and testing datasets
train.df <- lapply(train.df, function(x) {
x <- x[!colnames(x) %in% Vars_to_remove]
return(x)
})
train.df
train.df<-terra::extract(envData, myPres, df=TRUE)
train.df<-cbind.data.frame(PA=myPres$Observed,
train.df[,2:ncol(train.df)])
train.df[!colnames(train.df) %in% Vars_to_remove]
#get rid of correlated variables from training and testing datasets
train.df <- train.df[!colnames(train.df) %in% Vars_to_remove]
#check distribution of values of predictors for presence and absence data
ggarrange(plotlist = lapply(colnames(train.df), function(nm) {
ggplot(train.df, aes_string(x = nm)) +
geom_density(aes(fill = as.factor(PA)), alpha = .3) +
scale_fill_viridis_d() +
theme_classic()
}),
nrow = 2, ncol = 2)
?ggarrange
??ggarrange
#check distribution of values of predictors for presence and absence data
ggpubr::ggarrange(plotlist = lapply(colnames(train.df), function(nm) {
ggplot(train.df, aes_string(x = nm)) +
geom_density(aes(fill = as.factor(PA)), alpha = .3) +
scale_fill_viridis_d() +
theme_classic()
}),
nrow = 2, ncol = 2)
#check distribution of values of predictors for presence and absence data
ggpubr::ggarrange(plotlist = lapply(colnames(train.df), function(nm) {
ggplot(train.df, aes_string(x = nm)) +
geom_density(aes(fill = as.factor(PA)), alpha = .3) +
scale_fill_viridis_d() +
theme_classic()
}))
hist(train.df$bio2, xlab = "bio6", main = NULL)
hist(train.df$bio3, xlab = "bio7", main = NULL)
hist(train.df$bio8, xlab = "bio8", main = NULL)
Mod_VS <- glm(PA ~ ., family = binomial, data = train.df)
summary(Mod_VS)
car::S(Mod_VS) #Wald's test
car::Anova(Mod_VS) #Likelihood ratio test
car::vif(Mod_VS)
car::marginalModelPlots(Mod_VS)
#some diagnostics
car::residualPlots(Mod_VS) #include all poly(x, 2) terms
car::influenceIndexPlot(Mod_VS)
car::outlierTest(Mod_VS)
train.df
names(train.df)
#remove bio2
Mod_VS.2 <- glm(PA ~ bio2 + bio3 + bio8 +bio9 + bio13 + bio15,
family = binomial, data = train.df)
car::S(Mod_VS.2)
#remove bio2
Mod_VS.2 <- glm(PA ~ bio3 + bio8 +bio9 + bio13 + bio15,
family = binomial, data = train.df)
car::S(Mod_VS.2)
#compare nested model without bio2
anova(Mod_VS, Mod_VS.2, test = "Chisq")
car::marginalModelPlots(Mod_VS.2)
OOS.fitted <- predict(Mod_VS.2, newdata = train.df, type = "response")
OOS.tss <- ecospat.max.tss(Pred = OOS.fitted, Sp.occ = train.df$TPA)$max.TSS
OOS.fitted
OOS.tss <- ecospat.max.tss(Pred = OOS.fitted, Sp.occ = train.df$PA)$max.TSS
OOS.tss
OOS.boyce_ind <- ecospat.boyce(fit = OOS.fitted, obs = OOS.fitted[which(train.df$PA == 1)], nclass = 0,
window.w = "default", res = 100, PEplot = F)$Spearman.cor #check later details args
OOS.boyce_ind
OOS.boyce_ind <- ecospat.boyce(fit = OOS.fitted,
obs = OOS.fitted[which(train.df$PA == 1)],
nclass = 0,
window.w = "default", res = 100, PEplot = F)$cor #check later details args
OOS.boyce_ind
OOS.boyce_ind
#goodness-of-fit
performance::model_performance(Mod_VS.2) #Tjur's R2 = 0.347
(Mod_VS.2$null.deviance - Mod_VS.2$deviance)/Mod_VS.2$null.deviance #Deviance-based  R2 0.29
#same as Deviance-based R2
modEvA::Dsquared(Mod_VS.2) #0.29
modEvA::RsqGLM(Mod_VS.2)
#for multicollinearity issues see: https://stats.stackexchange.com/questions/141619/wont-highly-correlated-variables-in-random-forest-distort-accuracy-and-feature
RF_VS <- ranger::ranger(formula = PA~bio3 + bio8 +bio9 + bio13 + bio15,
importance = 'permutation',
data = train.df)
summary(RF_VS)
RF_VS
ranger::importance(RF_FagusEU)
ranger::importance(RF_VS)
#check range of (within-sample) predictions is within the unit interval [0, 1]
range(predict(object = RF_VS, data = train.df, type = "response")$predictions)
hist(predict(object = RF_VS, data = train.df, type = "response")$predictions)
#2) out-of-sample prediction (OOS)
OOS.fitted.RF <- predict(object = RF_VS, data = train.df, type = "response")$predictions
OOS.tss.RF <- ecospat.max.tss(Pred = OOS.fitted.RF, Sp.occ = train.df$PA)$max.TSS
OOS.tss.RF
OOS.boyce_ind.RF <- ecospat.boyce(fit = OOS.fitted.RF,
obs = OOS.fitted.RF[which(train.df$PA == 1)], nclass = 0,
window.w = "default", res = 100, PEplot = F)$.cor #check later details args
OOS.boyce_ind.RF
OOS.fitted.RF
OOS.boyce_ind.RF <- ecospat.boyce(fit = OOS.fitted.RF,
obs = OOS.fitted[which(train.df$PA == 1)],
nclass = 0,
window.w = "default", res = 100, PEplot = F)$.cor #check later details args
OOS.boyce_ind.RF
#goodness-of-fit
RF_VS$r.squared #0.6656922
RF_VS
sqrt(RF_VS$prediction.error)
pred.RF <- predict(object = RF_VS, data = envData, type = "response")$predictions
pred.GLM <- predict(Mod_VS.2, newdata = envData, type = "response")
pred.GLM <- raster::predict(Mod_VS.2, newdata = envData, type = "response")
#------USE-----------------
setwd("/home/ddare/GitHub/USE/")
# token
library(devtools)
library(roxygen2)
library(usethat)
# devtools::create("yourPkg")
# devtools::install_github("mattmar/dynamAedes")
devtools::load_all(".") # Working directory should be in the package directory
#update documentation
devtools::document()
#store template dataset
Worldclim <- geodata::worldclim_global(var='bio', res=10, path='/home/ddare/Downloads/')
Worldclim_tmp<-Worldclim[[ c(4,  3, 14,  9, 15)]]
Worldclim_tmp<-terra::crop(Worldclim_tmp, terra::ext(-12, 25, 36, 60))
plot(Worldclim_tmp$wc2.1_10m_bio_4)
Worldclim
#store template dataset
Worldclim <- geodata::worldclim_global(var='bio', res=10, path='/home/ddare/Downloads/')
Worldclim_tmp<-Worldclim[[ c(4,  3, 14,  9, 15)]]
Worldclim_tmp
library(terra)
plot(Worldclim_tmp$wc2.1_10m_bio_4)
Worldclim_tmp<-terra::crop(Worldclim_tmp, terra::ext(-12, 25, 36, 60))
plot(Worldclim_tmp$wc2.1_10m_bio_4)
Worldclim_tmp<-terra::as.data.frame(Worldclim_tmp, xy=TRUE)
Worldclim_tmp
usethis::use_data(Worldclim_tmp, overwrite = TRUE)
# Sys.setlocale("LC_ALL", "English")
library(geodata)
library(USE)
library(terra)
library(raster)
library(virtualspecies)
library(sf)
library(ggplot2)
# devtools::create("yourPkg")
# devtools::install_github("mattmar/dynamAedes")
devtools::load_all(".") # Working directory should be in the package directory
# devtools::create("yourPkg")
# devtools::install_github("mattmar/dynamAedes")
devtools::load_all(".") # Working directory should be in the package directory
#update documentation
devtools::document()
envData <- USE::Worldclim_tmp
envData
envData<-rast(envData,  type="xyz")
envData
#check everything is ok for the CRAN
devtools::check()#vignettes=FALSE
session_info()
