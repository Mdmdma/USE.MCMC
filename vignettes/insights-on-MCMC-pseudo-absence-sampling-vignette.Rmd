---
title: "insights-on-MCMC-pseudo-absence-sampling-vignette"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{insights-on-MCMC-pseudo-absence-sampling-vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

This vignette gives insights on how MCMC works and how it can be used to sample pseudo absences. It builds on ideas of neareast neighbor mapping. This concept is explained in detail in the [insights on nearest neighbor search](Insights-on-nearest-neighbor-search.html).
```{r setup, message=FALSE}
library(USE.MCMC)
library(terra)
library(virtualspecies)
library(sf)
library(ggplot2)
library(parallel)
library(FNN)
library(coda)
library(gganimate)
library(tcltk)
library(viridis)
library(cowplot)
library(entropy)
# fixing the
set.seed(42)
```

Before we can understand why Monte Carlo Markov chains are usefull, we have to understand how they work. 

For our use case Markov chains can be understood as a random walk. From a given starting point the chain starts to explore the given space. Given the current point we calculate the update step. In this case this step is two dimensional gaussian nosise. The algorithm then desides if it wants to accept this proposed point. In this first example we accept all points.

```{r generate-sample-chain, message=FALSE}
starting.point <- data.frame(x=0, y=0)
sampled.points <- USE.MCMC::mcmcSampling(dataset=starting.point,
                               dimensions = c("x", "y"),
                               densityFunction = alwaysOne,
                               proposalFunction = addHighDimGaussian(dim=2),
                               burnIn = FALSE, 
                               n.sample.points = 100,
                               verbose = FALSE)
```
```{r animate-sample-chain, eval=FALSE, echo=FALSE}
starting.point$density <- 1
sampled.points <- rbind(starting.point, sampled.points)
sampled.points$step <- 1:nrow(sampled.points)
p.example.chain <- ggplot(sampled.points) + 
  geom_point(aes(x=y, y=x, color=step)) + 
  geom_path(aes(x=y, y=x, color=step)) + 
  theme_minimal() +
  labs(title = "Example of a Random walk")  + 
  scale_color_viridis()

a.example.chain <- p.example.chain +
  transition_time(step) +
  ease_aes('linear') +
  transition_reveal(step) +
  exit_shrink() +
  shadow_trail(alpha = 0.3)

gif.example.chain <- gganimate::animate(a.example.chain, renderer = gifski_renderer(), width = 700, height = 600, fps = 10, duration = 4)
anim_save("gif_example_chain.gif", gif.example.chain)
```
![](gif_example_chain.gif)

In practical cases a Markov chain does not perform a completely random walk. The chain tries to replicate some kind of function. In the case above this function is one everywhere. Therefore the chain explores in all directions and without limit. In this unbound case the chain would not converge to some stationary state. We can supply the MCMC algorithm a function that represents the distribution we want to replicate. 

Lets make an example and create samples from a two dimensional Gaussian.

```{r generate-sample-gaussian-chain}
densityFunctionGaussian <- function(point, lengthscale=5){
  density <- exp(-(point$x ** 2 + point$y ** 2) / lengthscale)
}
d <- densityFunctionGaussian(sampled.points)
sampled.points.gaussian <- mcmcSampling(dataset=starting.point,
                                  dimensions = c("x", "y"),
                                  densityFunction = densityFunctionGaussian,
                                  proposalFunction = addHighDimGaussian(dim=2),
                                  burnIn = FALSE, 
                                  n.sample.points = 100,
                                  verbose = FALSE)
```
The further the chain wanders away from the origin the higher the probability gets that the proposed point gets rejected. 
```{r animate-sample-gaussian-chain, echo=FALSE, eval=FALSE}
starting.point$density <- 1
sampled.points.gaussian <- rbind(starting.point, sampled.points.gaussian)
sampled.points.gaussian$step <- 1:nrow(sampled.points.gaussian)
p.example.chain.gaussian <- ggplot(sampled.points.gaussian) + 
  geom_point(aes(x=y, y=x, color=step)) + 
  geom_path(aes(x=y, y=x, color=step)) + 
  theme_minimal() +
  labs(title = "100 samples from a Gaussian")  + 
  scale_color_viridis()

a.example.chain.gaussian <- p.example.chain.gaussian +
  transition_time(step) + ease_aes('linear') +
  transition_reveal(step) +
  exit_shrink() +
  shadow_trail(alpha = 0.3)

gif.example.chain.gaussian <- animate(a.example.chain.gaussian, renderer = gifski_renderer(), width = 700, height = 600, fps = 10, duration = 6)
anim_save("gif_example_chain_gaussian.gif", gif.example.chain.gaussian)
```

![](gif_example_chain_gaussian.gif)
As before the proposal step is completely random. The algorithm now decides if it wants to accept the proposed next point using the metropolis Hastings algorithm.
$$
\alpha = \frac{d(p')}{d(p)}, \quad p_{n+1} = \begin{cases}
        p' & \alpha >n, n\sim \mathcal{U}(0,1)  \\
        p_n & \text{otherwise}
    \end{cases}
$$
Given a point $p_n$ we calculate a proposed point $p'$. The function $d(p)$ now guides our chain. If the value of $d()$ is higher at the new location, the chain always continues. If the value of $d(p)$ is lower at the new location the chain sometimes transitions. This guaranties that the whole space is getting sampled.

Looking at the posterior of our sampled points, the distribution of x and y values of our points, we see that they resemble Gaussian, but our sample size was too small.
```{r gaussian-posterior-plot, echo=FALSE, fig.height=5, fig.width=7}
p.gaussian.posterior.x.limited.samplesize <- ggplot(sampled.points.gaussian) +
  geom_density(aes(x=x)) +
  xlim(-5,5)

p.gaussian.posterior.y.limited.samplesize <- ggplot(sampled.points.gaussian) +
  geom_density(aes(x=y)) +
  xlim(-5,5)

titled_plot <- plot_grid(
  draw_label("My Combined Plot Title", size = 14, fontface = "bold"),
  grid,
  ncol = 1,
  rel_heights = c(0.1, 1)
)

ggdraw() + 
  draw_plot(cowplot::plot_grid(p.gaussian.posterior.x.limited.samplesize,
                   p.gaussian.posterior.y.limited.samplesize,
                   ncol = 1),
            height = 0.9) +
  draw_label("Posterior of MCMC with 100 samples", 
             x = 0.5, y = 0.95, size = 16)
```
Increasing the sample size results in a better approximation.
```{r sample-gaussian-large-number-of-samples}
sampled.points.gaussian <- mcmcSampling(dataset=starting.point,
                                  dimensions = c("x", "y"),
                                  densityFunction = densityFunctionGaussian,
                                  proposalFunction = addHighDimGaussian(dim=2),
                                  burnIn = FALSE, 
                                  n.sample.points = 10000,
                                  verbose = FALSE)
```
```{r animate-sample-gaussian-chain-long, echo=FALSE, eval=FALSE}
starting.point$density <- 1
sampled.points.gaussian <- rbind(starting.point, sampled.points.gaussian)
sampled.points.gaussian$step <- 1:nrow(sampled.points.gaussian)
p.example.chain.gaussian <- ggplot(sampled.points.gaussian) + 
  geom_point(aes(x=y, y=x, color=step)) + 
  geom_path(aes(x=y, y=x, color=step)) + 
  theme_minimal() +
  labs(title = "10'000 samples from a Gaussian")  + 
  scale_color_viridis()

a.example.chain.gaussian <- p.example.chain.gaussian +
  transition_time(step) + ease_aes('linear') +
  transition_reveal(step) +
  exit_shrink() +
  shadow_trail(alpha = 0.3)

gif.example.chain.gaussian <- animate(a.example.chain.gaussian, renderer = gifski_renderer(), width = 700, height = 600, fps = 10, duration = 6)
anim_save("gif_example_chain_gaussian_long.gif", gif.example.chain.gaussian)
```
![](gif_example_chain_gaussian_long.gif)
```{r gaussian-posterior-plot-more-samples, echo=FALSE, fig.height=5, fig.width=7}
p.gaussian.posterior.x.limited.samplesize <- ggplot(sampled.points.gaussian) +
  geom_density(aes(x=x)) +
  xlim(-5,5)

p.gaussian.posterior.y.limited.samplesize <- ggplot(sampled.points.gaussian) +
  geom_density(aes(x=y)) +
  xlim(-5,5)

ggdraw() + 
  draw_plot(cowplot::plot_grid(p.gaussian.posterior.x.limited.samplesize,
                   p.gaussian.posterior.y.limited.samplesize,
                   ncol = 1),
            height = 0.9) +
  draw_label("Posterior of MCMC with 10000 samples", 
             x = 0.5, y = 0.95, size = 16)
```

In this low dimensional case with a simple function there are more simple ways to generate samples. The case where MCMC gets useful for sample generation is if the function is very complicated and expensive to compute and in case our problem lives in high dimensions. 

Lets explore the dimensionality issue first. If we compute the value of our function on a grid with 100 cells, a moderate resolution, that is 10'000 points in the two dimensional case. In the five dimensional case that are 10 billion. Computational and memory requirements become limiting factors for application of such approaches.

In case of MCMC sampling the computational complexity increases, but less fast. The function that we have to evaluate to decide if we want to accept a new point becomes more complex and we have to run the chain for longer until we have nice convergence. 

# Pseudo absence sampling

If we want to use MCMC to generate pseudo absences we first have to construct the function that represents the density of our pseudo absences in the environmental space. 

Here we demonstrate an approach using Gaussian mixtures. As the example above shows we can generate sample points from a Gaussian distribution. On the other hand we can also use sample points to find the Gaussian that is best at explaining the given data. In a Gaussian mixtures we do not only fit one Gaussian, but can find the number of Gaussian that is most probably at explaining the data. 

For the model to fit the data well it has to resemble a multi modal Gaussian. The environment does not necessarily have this structure. We therefore perform a pca to have a more simple structure in our data and reduce its dimensionality.

In a first step we have to descide the dimensions we want to unifromwly sample.
```{r set-dimesnions}
dimensions <- c("PC1", "PC2")
```

```{r load-data}
env.data.raster <- USE.MCMC::Worldclim_tmp %>%
  terra::rast(type="xyz") %>%
  round(2) 

rpc <- rastPCA(env.data.raster,  stand = TRUE)

env.data.raster.with.pc <- c(env.data.raster, rpc$PCs)

env.data.sf <- env.data.raster %>%
    as.data.frame(xy = TRUE) %>%
    sf::st_as_sf(coords = c("x", "y"))

  # Attaching the data in the PCA coordinates
env.with.pc.sf <- rpc$PCs %>%
  as.data.frame(xy = TRUE) %>%
  na.omit() %>%
  sf::st_as_sf(coords = c("x", "y")) %>%
  sf::st_join(env.data.sf)

env.data.cleaned <- sf::st_drop_geometry(env.with.pc.sf[dimensions])
```

To generate pseudo absences we use two Gaussian mixture models. In a first step we fit the points in our environment. This model is later used to stop our chain from wandering into areas where no points are found. 

```{r plot-env-data, message=FALSE, fig.height=4, fig.width=7}
p.points.in.the.environment <- ggplot() + 
  geom_point(data=env.data.cleaned,
             aes(x=PC1, y=PC2),
             color = "black", 
             size=0.2) + 
  labs(title = "Points of the environmeltal dataset",
       )
p.points.in.the.environment
```

We subsample the environment to speed up the computation. As fitting Gaussian mixtures is a statistical process and the dataset is still large this is justified. In addition to that this model is only used to keep the chain in bound. Other techniques are later used to exclude parts of the chain that are too far from the real data.

```{r fit-environmental-model, message=FALSE, fig.height=4, fig.width=7}
env.with.pc.sf.subsampled <- env.with.pc.sf[
  stats::runif(min(nrow(env.with.pc.sf), 2000) , 1, nrow(env.with.pc.sf)),]
env.data.cleaned.subsampled <- sf::st_drop_geometry(
  env.with.pc.sf.subsampled[dimensions])
environmental.data.model <- mclust::densityMclust(env.data.cleaned.subsampled)
title("Gaussian mixture fitted to the environment")
```

The model is a function that gives us the sum of the Gaussian components at each location. The higher the value the more probably it is to find a point at the given location. In our case we want to sample the environmental space uniformly, not reproduce the underlying distribution. We use this environmental model only to set the boundaries for our chain. 

The model density at the points in the environment can be used to find the threshold under which no points are expected any more.

```{r set-environmental-threshold}
environmental.densities <- mclust::predict.densityMclust(
  environmental.data.model, env.data.cleaned)
environmental.threshold <- stats::quantile(environmental.densities, 0.01)
```

We can now start to construct the function that our chain tries to sample from. 

```{r set-naive-density-funciton}
densityFunctionNaive <- function(env.model, env.threshold, dimensions){
  densityFunction <- function(point){
    point <- as.data.frame(point)
    point <- sf::st_drop_geometry(point[dimensions]) %>%
      as.matrix()
    env.density <- mclust::predict.densityMclust(env.model, point)
    if (env.density < env.threshold){
      return(0)
    } else {
      return(1)
    }
  }
}

densityFunction <- densityFunctionNaive(environmental.data.model,
                                        environmental.threshold,
                                        dimensions)
```
As we are in the two dimensional case we can plot the function.

```{r plot-simple-denisty, echo=FALSE, fig.height=4, fig.width=7}
gridsize <- 100
grid <- expand.grid(
  x = seq(min(env.data.cleaned$PC1), max(env.data.cleaned$PC1), length.out = gridsize),
  y = seq(min(env.data.cleaned$PC2), max(env.data.cleaned$PC2), length.out = gridsize)
)
names(grid) <- c("PC1", "PC2")

grid$density <- purrr::map_dbl(1:nrow(grid), ~ densityFunction(grid[.x, , drop = FALSE]))

p.density.naive <- ggplot() + 
  geom_tile(data=grid, aes(x=PC1, y=PC2, fill=density)) + 
  geom_point(data=env.data.cleaned, aes(x=PC1, y=PC2), size = 0.1) +
  theme_minimal() + 
  labs(title = "Density function in the naive case") 
  
print(p.density.naive)
```

We can now use the mcmc algorithm from before to generate samples from this function. 

```{r sample-naive-points}
sampled.points.naive.density <- mcmcSampling(dataset = env.with.pc.sf,
                                      dimensions = dimensions,
                                      densityFunction = densityFunction,
                                      n.sample.points = 5000,
                                      burnIn = FALSE)
```

```{r animate-naive-points, eval=FALSE}

sampled.points.naive.density$step <- 1:nrow(sampled.points.naive.density)
p.chain.naive.density <- ggplot(sampled.points.naive.density) + 
  geom_point(aes(x=PC1, y=PC2, color=step)) + 
  geom_path(aes(x=PC1, y=PC2, color=step)) + 
  theme_minimal() +
  labs(title = "Chain on naive GMM model")  + 
  scale_color_viridis()

a.chain.naive.density <- p.chain.naive.density +
  transition_time(step) + ease_aes('linear') +
  transition_reveal(step) +
  exit_shrink() +
  shadow_trail(alpha = 0.3)

gif.chain.naive.density <- animate(a.chain.naive.density, renderer = gifski_renderer(), width = 700, height = 400, fps = 10, duration = 10)
anim_save("chain.naive.density.gif", gif.chain.naive.density)
```
![](chain.naive.density.gif)

We now can sample our environmental space uniformely. Pseudo absences should not only be uniformly distributed but also evade the conditions under which the species we try to model flourishes. 

```{r generate-virtual-species}
virtual.presence.data <- getVirtualSpeciesPresencePoints(
  env.data = env.data.raster.with.pc, n.samples = 300)
virtual.presence.points <- virtual.presence.data$sample.points
virtual.presence.points.pc <- terra::extract(env.data.raster.with.pc,
                                             virtual.presence.points,
                                             bind = TRUE) %>%
  sf::st_as_sf()
```

As before we can fit a gaussian mixture to the given datapoints

```{r fit-species-model, message=FALSE, fig.height=4, fig.width=7}
species.model = mclust::densityMclust(sf::st_drop_geometry(virtual.presence.points.pc[dimensions]))
species.densities <- species.model$density
species.cutoff.threshold <- stats::quantile(species.densities, 0.9)
title("Gaussian mixture model fitted to the target species")

```

Now we can build a function that describes the distribution of pseudo absences. To evade the presence we subtract something in areas with species occurrence. The density of the presence model therefor has to be scaled. We do this by selecting the density at a given quantile of the presence points and scale the whole function so that the value becomes 1. As we subtract it from the former function value, we now get values below zero in these areas, meaning we will never visit them with the chain.

```{r full-pseudo-absence-density-funciton}
densityFunctionPseudoAbsences <- function(env.model, env.threshold,
                                  pres.model, pres.threshold, 
                                  dimensions){
  densityFunction <- function(point){
    point <- sf::st_drop_geometry(point[dimensions]) %>%
      as.matrix()
    env.density <- mclust::predict.densityMclust(env.model, point)
    if (env.density < env.threshold){
      return(0)
    } else {
      return(
        max(0, 1-mclust::predict.densityMclust(pres.model, point) / pres.threshold)
        )
    }
  }
}

densityFunction <- densityFunctionPseudoAbsences(environmental.data.model,
                                                 environmental.threshold,
                                                 species.model,
                                                 species.cutoff.threshold,
                                                 dimensions)
```

As before we can plot the function we want to sample from.

```{r plot-pseudo-absence-density, echo=FALSE, fig.height=4, fig.width=7}
grid$density <- purrr::map_dbl(1:nrow(grid), ~ densityFunction(grid[.x, , drop = FALSE]))

p.density.pseudo.absence <- ggplot() + 
  geom_tile(data=grid, aes(x=PC1, y=PC2, fill=density)) + 
  geom_point(data=virtual.presence.points.pc, aes(x=PC1, y=PC2, color="Presence"), size = 0.1) +
  scale_color_manual(values = c("Presence" = "red"),
                     name = "Point type") + 
  theme_minimal() + 
  labs(title = "Value of the pseudo absence function") 
  
p.density.pseudo.absence
```


```{r sample-pseudo-absences}
sampled.points.ps.density <- mcmcSampling(dataset = env.with.pc.sf,
                                      dimensions = dimensions,
                                      densityFunction = densityFunction,
                                      n.sample.points = 5000,
                                      burnIn = TRUE)
```

```{r animate-pseudeo-absences, eval=FALSE}

sampled.points.ps.density$step <- 1:nrow(sampled.points.ps.density)
p.chain.ps.densitycom <- ggplot(sampled.points.ps.density) + 
  geom_point(aes(x=PC1, y=PC2, color=step)) + 
  geom_path(aes(x=PC1, y=PC2, color=step)) + 
  theme_minimal() +
  labs(title = "Chain on full pseudo absence model")  + 
  scale_color_viridis()

a.chain.ps.density <- p.chain.ps.density +
  transition_time(step) + ease_aes('linear') +
  transition_reveal(step) +
  exit_shrink() +
  shadow_trail(alpha = 0.3)

gif.chain.ps.density <- animate(a.chain.ps.density, renderer = gifski_renderer(), width = 700, height = 400, fps = 10, duration = 10)
anim_save("chain.ps.density.gif", gif.chain.ps.density)
```
![](chain.ps.density.gif)

So far the sample points are not contained in the environment. They only have values for the dimension we wanted to sample. To get real points again we use the nearest neighbor search. The technique is further described in [insights on nearest neighbor search](Insights-on-nearest-neighbor-search.html). The core of the idea is that we can compute the distance from a sample point to other points in the dataset and choose the point with the shortest distance to represent our sample point. 

```{r remapping}
sampled.points <- sampled.points.ps.density
mapped.sampled.point.locations <- FNN::get.knnx(
  env.data.cleaned[dimensions], sampled.points[dimensions],k = 1)
mapped.sampled.points <- env.with.pc.sf[
  mapped.sampled.point.locations$nn.index,]
mapped.sampled.points$density <- sampled.points$density
mapped.sampled.points$distance <- mapped.sampled.point.locations$nn.dist
```
Now we have real points in our environemnt with a geographical location. The model of our environment is not perfect. The distance to the remapped point gives an indication on how far the chain wandered of the real data points. We can use it to filter points that originated in areas where our environmental model was bad. The distance that lays between a point and its origin should never be more than half the maximal distance between points in the dataset. 

```{r neighbor-distance-threshold}
nearest.neighbors.distance<- FNN::knn.dist(env.data.cleaned[dimensions],
                                           k=3) %>%
  as.vector()

sorted.nearest.neighbor.distances <- sort(nearest.neighbors.distance, 
                                          decreasing=TRUE)
distance.threshold <- sorted.nearest.neighbor.distances[2] / 2

mapped.sampled.points.filtered <- mapped.sampled.points[
  mapped.sampled.points$distance < distance.threshold, ]
```

In a last step we can select the desired number of points from our chain.

```{r thinning}
n.samples <- 300
mapped.sampled.points.selected <- mapped.sampled.points.filtered[
  runif(n.samples, 0, nrow(mapped.sampled.points.filtered)), ]
```


We can look at out points in the environmental space

```{r points-in-the-environment, echo=FALSE, fig.height=4, fig.width=7}
p.points.in.the.environment <- p.density.pseudo.absence + 
  geom_point(data=mapped.sampled.points.selected,
             aes(x=PC1, y=PC2, color="Pseudo-absence"),
             , 
             size=0.2) + 
  geom_point(data=virtual.presence.points.pc,
             aes(x=PC1, y=PC2, color="Presence"),
             size=0.2) +
  scale_color_manual(values = c("Presence" = "red", "Pseudo-absence" = "black"),
                     name = "Point type") +
  labs(title = "Sampled points in the environmental space")
p.points.in.the.environment
```

Looking at the posteriors we can see that we managed to sample the environmental space uniformly.

```{r mcmc-posterior, echo=FALSE, fig.height=5, fig.width=7}
p.mcmc.posterior.pc1 <- ggplot() +
  geom_density(data=mapped.sampled.points.selected, aes(x=PC1, color="Pseudo-absence")) +
  geom_density(data=env.data.cleaned, aes(x=PC1, color="Environment")) + 
  geom_density(data=virtual.presence.points.pc, aes(x=PC1, color="Presence")) +
  scale_color_manual(values = c("Presence" = "red", "Pseudo-absence" = "black", "Environment" = "green"),
                     name = "Point type")

p.mcmc.posterior.pc2 <- ggplot() +
  geom_density(data=mapped.sampled.points.selected, aes(x=PC2, color="Pseudo-absence")) +
  geom_density(data=env.data.cleaned, aes(x=PC2, color="Environment")) + 
  geom_density(data=virtual.presence.points.pc, aes(x=PC2, color="Presence")) +
  scale_color_manual(values = c("Presence" = "red", "Pseudo-absence" = "black", "Environment" = "green"),
                     name = "Point type")

p.mcmc.posterior.pc3 <- ggplot() +
  geom_density(data=mapped.sampled.points.selected, aes(x=PC3, color="Pseudo-absence")) +
  geom_density(data=env.with.pc.sf, aes(x=PC3, color="Environment")) + 
  geom_density(data=virtual.presence.points.pc, aes(x=PC3, color="Presence")) +
  scale_color_manual(values = c("Presence" = "red", "Pseudo-absence" = "black", "Environment" = "green"),
                     name = "Point type")

ggdraw() + 
  draw_plot(cowplot::plot_grid(p.mcmc.posterior.pc1,
                   p.mcmc.posterior.pc2,
                   p.mcmc.posterior.pc3,
                   ncol = 1),
            height = 0.9) +
  draw_label("Posterior of compared to Presence and environment", 
             x = 0.5, y = 0.95, size = 16)



```
For the selected dimensions the posterior is flat, for the other ones, in this case principal component three the distribution follows the environment. 

The sampled points can also be plotted in the geographical space.
```{r plot-in-geo, echo=FALSE, fig.height=4, fig.width=7}
sf::st_crs(mapped.sampled.points.selected) <- 4326
sf::st_crs(virtual.presence.points.pc) <- 4326
sf::st_crs(env.data.sf) <- 4326
p.sampled.points.in.geographical.space <- ggplot() +
  geom_sf(data=env.data.sf, aes(color="Environment"), size=0.02, show.legend = FALSE) +
  geom_sf(data=mapped.sampled.points.selected, aes(color="Pseudo-absence"), size=1) + 
  geom_sf(data=virtual.presence.points.pc, aes(color="Presence"), size=1) + 
  scale_color_manual(values = c("Presence" = "red", "Pseudo-absence" = "black", "Environment" = "lightgreen"),
                     breaks = c("Presence", "Pseudo-absence"),
                     name = "Point type") + 
  theme_minimal() + 
  labs(title="Sampled points in the geographical space")
p.sampled.points.in.geographical.space
```

So far we did nothing revolutionary. All of the given can be done using existing techniques.The advantage emerges when we want to increase the dimensions included. The only thing that has to change is the vector from the beginning in which we stated the dimensions to include. As the results are getting difficult to represent in 2d plots, we focus on the results of such computations. 

The function paSamplingMcmc wrapps what we did so far in this vignette into one single concise function to efficiently create pseudo absences.

```{r sample-in-higher-dim}
# One core is used for rendering the vignette, is use this can be set higher
sampled.points.mcmc.higher.dim <- paSamplingMcmc(env.data.raster = env.data.raster,
                                      pres = virtual.presence.points,
                                      precomputed.pca = rpc,
                                      environmental.cutof.percentile = 0.001,
                                      num.chains = 4,
                                      num.cores = 1,
                                      chain.length = 10000,
                                      n.samples = 500,
                                      verbose = TRUE,
                                      dimensions = c("PC1", "PC2", "PC3"))
```
By including the third dimension into the algorithm we now get a flat posterior also from it.

```{r plot-3d, echo=FALSE, fig.height=5, fig.width=7}
p.mcmc.posterior.pc1 <- ggplot() +
  geom_density(data=sampled.points.mcmc.higher.dim, aes(x=PC1, color="Pseudo-absence")) +
  geom_density(data=env.with.pc.sf, aes(x=PC1, color="Environment")) + 
  geom_density(data=virtual.presence.points.pc, aes(x=PC1, color="Presence")) +
  scale_color_manual(values = c("Presence" = "red", "Pseudo-absence" = "black", "Environment" = "green"),
                     name = "Point type")

p.mcmc.posterior.pc2 <- ggplot() +
  geom_density(data=sampled.points.mcmc.higher.dim, aes(x=PC2, color="Pseudo-absence")) +
  geom_density(data=env.with.pc.sf, aes(x=PC2, color="Environment")) + 
  geom_density(data=virtual.presence.points.pc, aes(x=PC2, color="Presence")) +
  scale_color_manual(values = c("Presence" = "red", "Pseudo-absence" = "black", "Environment" = "green"),
                     name = "Point type")

p.mcmc.posterior.pc3 <- ggplot() +
  geom_density(data=sampled.points.mcmc.higher.dim, aes(x=PC3, color="Pseudo-absence")) +
  geom_density(data=env.with.pc.sf, aes(x=PC3, color="Environment")) + 
  geom_density(data=virtual.presence.points.pc, aes(x=PC3, color="Presence")) +
  scale_color_manual(values = c("Presence" = "red", "Pseudo-absence" = "black", "Environment" = "green"),
                     name = "Point type")

ggdraw() + 
  draw_plot(cowplot::plot_grid(p.mcmc.posterior.pc1,
                   p.mcmc.posterior.pc2,
                   p.mcmc.posterior.pc3,
                   ncol = 1),
            height = 0.9) +
  draw_label("Posterior of compared to Presence and environment", 
             x = 0.5, y = 0.95, size = 16)
```
# Conververnce
A topic not cover so far is convergence. The reason why we use MCMC is to reduce computational complexity of our problem. Therefore we have to know how long we have to run the algorithm and how many chains we should combine to get satisfying results. 

To evaluate these issues lets first generate some long chains. 


```{r highe-dim-convergence, fig.height=4, fig.width=7}
dimensions <- c("PC1", "PC2", "PC3")
# Environmental model in 3 dimensions
env.with.pc.sf.subsampled <- env.with.pc.sf[
  stats::runif(min(nrow(env.with.pc.sf), 2000) , 1, nrow(env.with.pc.sf)),] %>%
  sf::st_drop_geometry()
  
env.data.cleaned.subsampled <- sf::st_drop_geometry(
  env.with.pc.sf.subsampled[dimensions])
environmental.data.model <- mclust::densityMclust(env.data.cleaned.subsampled)

env.data.cleaned <- sf::st_drop_geometry(env.with.pc.sf[dimensions])

environmental.densities <- mclust::predict.densityMclust(
  environmental.data.model, env.data.cleaned)
environmental.threshold <- stats::quantile(environmental.densities, 0.04)

#species model in 3 dimensions
species.model = mclust::densityMclust(sf::st_drop_geometry(virtual.presence.points.pc[dimensions]))
species.densities <- species.model$density
species.cutoff.threshold <- stats::quantile(species.densities, 0.9)

covariance.scaling <-0.075
covariance.matrix <- stats::cov(sf::st_drop_geometry(env.with.pc.sf)[dimensions])
proposalFunction <- addHighDimGaussian(cov.mat =covariance.scaling * covariance.matrix,
                                       dim = length(dimensions))


densityFunction <- mclustDensityFunction(env.model = environmental.data.model,
                                         species.model = species.model,
                                         dim = dimensions,
                                         threshold = environmental.threshold,
                                         species.cutoff.threshold = species.cutoff.threshold)

chain.list <- list()
chain.list <- mclapply(1:4, function(i) {
  capture.output({
    sampled.points <- mcmcSampling(dataset = env.with.pc.sf.subsampled,
                                   dimensions = dimensions,
                                   n.sample.points = 5000,
                                   densityFunction = densityFunction,
                                   proposalFunction = proposalFunction,
                                   burnIn = TRUE,
                                   verbose = FALSE)
  })
  chain.list[[i]] <- coda::as.mcmc(sampled.points[dimensions])
}, mc.cores = 1)
coda.chain.list <- coda::mcmc.list(chain.list)
```  

We can now look at the Gelman-Rubin plot of the chain ensemble. For the second and third principle component convergence is reached, looking at the first principle component it seems like the chain should run for longer. The needed runtime depends on how complex the environmental space is and on the number of dimensions included.
```{r gelman-plot, fig.height=5, fig.width=7}
coda::gelman.plot(coda.chain.list)
```
Entropy is a measure for information. The higher the entropy, the more information a dataset contains. We can plot how the entropy of a chain evolves over time
```{r entropy-plot, echo=FALSE, fig.height=5, fig.width=7, message=FALSE, warning=FALSE}
plot_entropy <- function(chain.list){
  interval <-  floor(seq(1,nrow(chain.list[[1]]), length.out = 100))
  results <- data.frame(interval = numeric(0), Hn = numeric(0), chain_id = integer(0))
  for (i in seq_along(chain.list)) {
    chain <- chain.list[i]

    # Calculate entropy for each interval and store it in a temporary data frame
    H <- sapply(interval, function(nrow) entropy(as.matrix(chain)[1:nrow, ]))

    # Add the results for the current chain to the results data frame
    results <- rbind(results, data.frame(interval = interval, H = H, chain_id = rep(i, length(interval))))
  }

  # Now create the plot
  plot <- ggplot(results, aes(x = interval, y = H, color = as.factor(chain_id))) +
    geom_line() +
    labs(color = "Chain",
         y = "Entopy",
         x = "Points included until",
         title = paste0("Entropy along the Chain in ",dim(as.matrix(chain.list[1]))[2]," dimensions"))+
    theme_minimal() +
    ylim(0,max(100, min(results)))
  return(plot)
}
p.entropy <- plot_entropy(coda.chain.list)
print(p.entropy)
```

We see that the entropy of the chain ensemble increases over time. This is to be expected, as the number of data points increases. The more important metric is the entropy is the entropy at a given number of points.







